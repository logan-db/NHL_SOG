# This is a Databricks asset bundle definition for nhlPredict.
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.
bundle:
  name: nhlPredict

# Variables for dynamic date calculation
variables:
  removal_date:
    description: "Date for resource removal (today + 2 months)"
    default: "2025-11-09"  # This will be calculated dynamically

include:
  - resources/*.yml

targets:
  # The 'dev' target, for development purposes. This target is the default.
  dev:
    # We use 'mode: development' to indicate this is a personal development copy:
    # - Deployed resources get prefixed with '[dev my_user_name]'
    # - Any job schedules and triggers are paused by default
    # - The 'development' mode is used for Delta Live Tables pipelines
    mode: development
    default: true
    workspace:
      host: https://e2-demo-field-eng.cloud.databricks.com
      artifact_path: /Volumes/lr_nhl_demo/dev/${workspace.current_user.short_name}/data
    # sync:
    #   include:
    #       - nhlPredict/src/data/2025_26_official_nhl_schedule_by_day.csv
    #       - nhlPredict/src/data/8477493.csv
    #       - nhlPredict/src/data/team_code_mappings.csv
    artifacts:
      player_data_upload:
        path: /Users/logan.rupert/Library/CloudStorage/GoogleDrive-logan.rupert@databricks.com/My Drive/Repositories/NHL_SOG/nhlPredict/src/data/8477493.csv
        type: csv
        files: 
          - source: "/Users/logan.rupert/Library/CloudStorage/GoogleDrive-logan.rupert@databricks.com/My Drive/Repositories/NHL_SOG/nhlPredict/src/data/8477493.csv"
      schedule_upload:
        path: /Users/logan.rupert/Library/CloudStorage/GoogleDrive-logan.rupert@databricks.com/My Drive/Repositories/NHL_SOG/nhlPredict/src/data/2025_26_official_nhl_schedule_by_day.csv
        type: csv
        files: 
          - source: "/Users/logan.rupert/Library/CloudStorage/GoogleDrive-logan.rupert@databricks.com/My Drive/Repositories/NHL_SOG/nhlPredict/src/data/2025_26_official_nhl_schedule_by_day.csv"
      mappings_upload:
        path: /Users/logan.rupert/Library/CloudStorage/GoogleDrive-logan.rupert@databricks.com/My Drive/Repositories/NHL_SOG/nhlPredict/src/data/team_code_mappings.csv
        type: csv
        files: 
          - source: "/Users/logan.rupert/Library/CloudStorage/GoogleDrive-logan.rupert@databricks.com/My Drive/Repositories/NHL_SOG/nhlPredict/src/data/team_code_mappings.csv"
  
  ## Optionally, there could be a 'staging' target here.
  ## (See Databricks docs on CI/CD at https://docs.databricks.com/dev-tools/bundles/ci-cd.html.)
  #
  # staging:
  #   workspace:
  #     host: https://e2-demo-field-eng.cloud.databricks.com

  # The 'prod' target, used for production deployment.
  prod:
    # We use 'mode: production' to indicate this is a production deployment.
    # Doing so enables strict verification of the settings below.
    mode: production
    workspace:
      host: https://e2-demo-field-eng.cloud.databricks.com
      # We always use /Users/logan.rupert@databricks.com for all resources to make sure we only have a single copy.
      # If this path results in an error, please make sure you have a recent version of the CLI installed.
      root_path: /Users/logan.rupert@databricks.com/.bundle/${bundle.name}/${bundle.target}
    run_as:
      # This runs as logan.rupert@databricks.com in production. We could also use a service principal here,
      # see https://docs.databricks.com/dev-tools/bundles/permissions.html.
      user_name: logan.rupert@databricks.com
